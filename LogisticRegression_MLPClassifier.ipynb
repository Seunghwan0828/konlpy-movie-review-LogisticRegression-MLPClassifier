{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: JPype1>=0.5.7 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from konlpy) (0.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from gensim) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.9.238)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.238 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.238)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.238->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.238->boto3->smart-open>=1.8.1->gensim) (0.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\jshwa\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jshwa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_fname = 'c:/windows/fonts/gulim.ttc'     # A font of your choice\n",
    "font_name = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, 'r', encoding='UTF8') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data\n",
    "train_data = read_data('C:\\\\Users\\\\jshwa\\\\Downloads\\\\ratings_train.txt')\n",
    "test_data = read_data('C:\\\\Users\\\\jshwa\\\\Downloads\\\\ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n",
      "3\n",
      "50000\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(train_data[0]))\n",
    "print(len(test_data))\n",
    "print(len(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jshwa\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 489.943608s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.utils import pprint\n",
    "pos_tagger = Okt()\n",
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "train_docs = [(tokenize(row[1]), row[2]) for row in train_data]\n",
    "test_docs = [(tokenize(row[1]), row[2]) for row in test_data]\n",
    "\n",
    "end = time()\n",
    "print('Time: {:f}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "\n",
    "tagged_train_docs = [TaggedDocument(d, [c]) for d, c in train_docs]\n",
    "tagged_test_docs = [TaggedDocument(d, [c]) for d, c in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "doc_vectorizer = doc2vec.Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.025, seed=1234)\n",
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs,epochs=10,total_examples=doc_vectorizer.corpus_count)\n",
    "    doc_vectorizer.alpha -= 0.002  \n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "train_y = [doc.tags[0] for doc in tagged_train_docs]\n",
    "test_x = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]\n",
    "test_y = [doc.tags[0] for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67726"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=1234)\n",
    "classifier.fit(train_x, train_y)\n",
    "classifier.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,),\n",
    "    max_iter=30,\n",
    "    alpha=1e-4,\n",
    "    solver='adam',\n",
    "    verbose=10,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60085438\n",
      "Iteration 2, loss = 0.57894384\n",
      "Iteration 3, loss = 0.57065608\n",
      "Iteration 4, loss = 0.56575273\n",
      "Iteration 5, loss = 0.56176644\n",
      "Iteration 6, loss = 0.55803160\n",
      "Iteration 7, loss = 0.55416094\n",
      "Iteration 8, loss = 0.55142271\n",
      "Iteration 9, loss = 0.54860672\n",
      "Iteration 10, loss = 0.54612909\n",
      "Iteration 11, loss = 0.54367273\n",
      "Iteration 12, loss = 0.54187194\n",
      "Iteration 13, loss = 0.53873423\n",
      "Iteration 14, loss = 0.53760300\n",
      "Iteration 15, loss = 0.53522622\n",
      "Iteration 16, loss = 0.53347028\n",
      "Iteration 17, loss = 0.53211238\n",
      "Iteration 18, loss = 0.53025743\n",
      "Iteration 19, loss = 0.52850564\n",
      "Iteration 20, loss = 0.52736591\n",
      "Iteration 21, loss = 0.52655419\n",
      "Iteration 22, loss = 0.52567531\n",
      "Iteration 23, loss = 0.52421873\n",
      "Iteration 24, loss = 0.52363034\n",
      "Iteration 25, loss = 0.52326937\n",
      "Iteration 26, loss = 0.52206635\n",
      "Iteration 27, loss = 0.52110613\n",
      "Iteration 28, loss = 0.51983560\n",
      "Iteration 29, loss = 0.51967516\n",
      "Iteration 30, loss = 0.51910215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jshwa\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 70.06%\n",
      "Time: 27.424693s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model.fit(train_x, train_y)\n",
    "y_pred = model.predict(test_x)\n",
    "acc = accuracy_score(y_pred, test_y)\n",
    "end = time()\n",
    "print(\"테스트 정확도: {:.2f}%\".format(acc*100))\n",
    "print('Time: {:f}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5주차 과제.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
